{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 4580|5580: Data Science\n",
    "## Lab 7: Logistic Regression, AUC and Random Forests\n",
    "\n",
    "#### Full name: Sharvita Paithankar\n",
    "#### Student ID: 108172438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given enough data, Logisitic Regression should always do at least as well as Naive Bayes on binary-feature data. Let's try that out on the text dataset (named <b>words</b>) that can be downloaded from Canvas under Lab 7. Place it in the same directory as this notebook and unzip it.\n",
    "\n",
    "We'll also need the <b>MNIST</b> data from the last lab (Lab 6, but also available under Lab 7). Download it from Canvas and put it under the same directory as this notebook and unzip it.\n",
    "\n",
    "First, load the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "iwords = np.loadtxt(\"words.imat.txt\")          # training data matrix in nnz x 3 form - rows are (doc, word, count) triples\n",
    "traincats = np.loadtxt(\"cats.imat.txt\")        # training labels in an ntrain x ncats matrix\n",
    "tiwords = np.loadtxt(\"testwords.imat.txt\")     # test data matrix in nnz x 3 form\n",
    "testcats = np.loadtxt(\"testcats.imat.txt\")     # test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data come as dense matrices with (row, col, val) triples in their rows. But they represent sparse matrices so we do the conversion next. Note that the matrix constructor uses wordcount>0 tests instead of the actual word counts which has the effect of making the word features binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sp.csr_matrix((iwords[:,2].astype(\"int\") > 0, (iwords[:,1].astype(\"int\"), iwords[:,0].astype(\"int\"))))\n",
    "ntrain = train.shape[0]\n",
    "nfeats = train.shape[1]\n",
    "\n",
    "test = sp.csr_matrix((tiwords[:,2] > 0, (tiwords[:,1], tiwords[:,0])),shape=(4000,nfeats))  # need to match the number of cols (words)\n",
    "ntdocs = test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we will concentrate on one label category, Category 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincat6 = traincats[:,6]\n",
    "testcat6 = testcats[:,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll import a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrclassifier = LogisticRegression(max_iter=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and train it on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrclassifier.fit(train,traincat6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lrclassifier.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q1: compute the accuracy of the predictions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91025"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: add code to score here (hint: this can be done in a single line of code)\n",
    "accuracy = np.mean(preds == testcat6);\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q2: How does this compare with Naive Bayes? In case you don't have the results handy, lets do it here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BernoulliNB docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.756"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "# TODO: add code to train, predict, score here (see sklearn documentation above for more info)\n",
    "nbclassifier = BernoulliNB()\n",
    "nbclassifier.fit(train,traincat6)\n",
    "preds = nbclassifier.predict(test)\n",
    "np.mean(preds == testcat6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond Accuracy: ROC and AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label prediction accuracy is a useful but sometimes misleading measure. E.g., for data with 10% positives, a predictor that always says \"no\" will be 90% accurate. It is also very often useful to control the ratio of positive/negative labels to minimize a loss function. E.g., false positives are generally more acceptable in computational marketing (it means you show an ad to someone who might not be interested) than false negatives (you failed to show an ad to someone who might be interest, and might generate some revenue for you). \n",
    "\n",
    "Logistic Regression computes the probability of a label and that output is useful for both richer evaluation methods, and for making more careful tradeoffs between positives and negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC (Receiver-Operator Characteristic) curve is a very useful tool for interpreting classifier performance. See the background material here:\n",
    "https://en.wikipedia.org/wiki/Receiver_operating_characteristic .\n",
    "It shows the classifiers TPR (True-Positive Rate) vs FPR (False-Positive Rate) at various thresholds. The threshold isnt shown on the plot but can be inferred later. TPR and FPR are defined as:\n",
    "\n",
    "* TPR = TP / (TP + FN)   # based only on actual positive instances\n",
    "* FPR = FP / (FP + TN)   # based only on actual negative instances\n",
    "\n",
    "where TP = true positive, FN = false negative (actually a positive which is mislabelled), etc. \n",
    "Neither quantity involves a mix of positives and negatives. So ROC curves are insensitive to the actual ratio of positives to negatives. \n",
    "\n",
    "To use ROC, we first use a modified version of the \".predict\" method which returns label probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = lrclassifier.predict_proba(test);\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From which you can see that there are 2 columns, i.e., one probability of false and one for true. Verify that the sum of every row is 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(preds,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the probabilities of cat6 membership = true, which is column 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds6 = preds[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we'll do a ROC plot for it. ROC plots represent the performance of a classifier over a range of possible threshold values, showing the true positive rate and false positives rates at those thresholds. In Python, do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "rc = roc_curve(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the X and Y coordinates of the ROC plot. To see it, do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1195dfd00>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYMUlEQVR4nO3de2xc53nn8e8zw6tIiqJISrSpC2VHlq24tldm7DhpEufiWnJ2V2kbdO20TddoV/A2Dlp0/7BRtM1ijUXT7S1N40RVUyNoC9RFa6NxtrKddIPGaV23plBdLPkiWnJESrZEXShKvM7l2T9mSA5HFHkkzfDMOfP7AATnnPPOzPNK1E8vz5zzvubuiIhI9CXCLkBEREpDgS4iEhMKdBGRmFCgi4jEhAJdRCQmasJ6446ODu/p6Qnr7UVEImnPnj2n3b1zvmOhBXpPTw99fX1hvb2ISCSZ2Y8ud0ynXEREYkKBLiISEwp0EZGYUKCLiMSEAl1EJCYWDXQze8rMTpnZa5c5bmb2VTPrN7P9Zral9GWKiMhigozQvwVsXeD4NmBj/msH8I1rL0tERK7Uotehu/tLZtazQJPtwJ97bh7eV8xshZld5+7vlqhGEaly7k4m66Szc7+fG5viwkSaTDZLJgvpbHbm+LEzYyQThudeIPc6sw9x97nb+X2z7zm933HPHZ/e7/mtwtnH3Rdu57MN6e1ZyUdvmvfeoGtSihuLuoGBgu3B/L5LAt3MdpAbxbNu3boSvLVI5chmnUw+eLKeC5XzYynGpjILPu+14+fJBFyXYP/g8Ew4TAdIdub7bEhli445Tjab+35g8DztzfUzrzkndArCDRYOuPnaecHOwmM+z2sUvyeXaf/eyESgP5soeeRjN1ZsoNs8++b96XT3XcAugN7eXq2sIWXn7kymswyeGyeTdVKZ6RFclvfOTzI2lWYinWXvsWFaGmrI5EM5mx/lTYf0kaFREgmDfFCnM04qm+XI0CgAZpcGUzl1NNdjBgkDw3LfzfL75n435u5b3ljL0IVJbrmuBbPcP9/pf8S5TSt4nNuafTx7rHgfc9pf+rqzj+cew+a+7nzveWZ0ktvXrCCZNGoSRjKRoCaR63ddTYKu1sb8/tmvhBntTXXU1yYwrOi1bc77FPYhSDubKf7S/fM9r7Df5VSKQB8E1hZsrwFOlOB1pQqlM1neOTPKubFUbqQ7HbCeHwHnt0+NTDCRys6MhNOZXEh/79BJMlnn8KmLJCw3ar0SbctqZ8KgJmEkCsLh1MgEvT0rqU3m9tUkE7z/+lbSmSwbVzXn2lruOdPhknWnsTY5Z0RcLJN1bu5qobEuGajGVS0N1NXoAjW5VCkC/TngUTN7GrgbOK/z5/Hg+SBNZbK5c5YZZyyV5uTIZP5XeSeTzQWS+9zTDW+fGqWuJkEqkyWVcdKZLP8+MMyKxlomM1nGpzLsGximramOdL7NRCrDmdGpq653epTc2ljLRzZ2sKatkc6WBuprEkyms9zc1UIyYflATlCbMJobauhqbaCproam+tCmNhIpiUV/gs3sr4B7gQ4zGwS+BNQCuPtOYDfwANAPjAEPl6tYKZ2Lk2kuTqSZSmc5PjzO2FSayXSWvQPDvPz2ac5cnOLd8+U5d3lDZxN1yQTtzXU01iZZ376c2mSC2mTuV9JVLfXcuKqZzub6OSPkhDHzOJkwWhpqaFtWR03SqEkkSCbK/yutSCULcpXLQ4scd+ALJatISm4ynWHg7BjHzo7xf154k6OnR5lMZxd8zp3r27hj7Qq6WhvoaK6fHdUmjUzW6eloyp1eMCORYOZUw3TYGtDd1khdTYLa/POSCVuS84gi1Uq/Y0bc6GSaA8fPc/T0aG7Encly+OQF3njvAmNTGUYmUgyPpS553qdvu467elbSXF9DbU2CFY21rF6eOz3R2VKv0w8iEaR/tRHyD4dO8t1D73H41EVGxlNMZbIMnB2/bPu1Kxu5f3MXiYSxpq2RruUNvG9VM7etadVIWSSGFOgV6tCJEX7vu2/yT/2naahJMDKRnnN89fJ6PnhDOx+6oYP62gQ/vWUNnS31tDfXUZdMKLBFqpACPWRvnbzADw+f5tzoFM/tO8FkOsPJkcmZ49e1NrBxdQubVjeTyjifu3sdN61uCbFiEalUCvQlMpHKMDqZpv/URQ4cP8/33zjFubEUr787MtOmJmHc//4uOlvqyWSd7XdcT2/PyhCrFpEoUaCX2NhUmmf2DDI4PM7RoVHeHrrI2/m7CYu1NtbyqVtW8dNb1nD3De001Seprwl2c4mISDEFeom8cuQMX37+DfYODM/sa2+q4+brWtiyro2pTJYt69owgx/rbmVDRxMrltWFWLGIxI0C/Sr1vXOWr36/nwODw5wruCywsTbJo594H5+/Zz0tDbUhVigi1UaBfgXcnW/84G2e+qd3OH1x9oPL/9K7luaGGn7ug+vZ0NEUYoUiUs0U6AG4O6cvTvGZJ/+Z48O5677Xty/jNz69mXs3dVKb1ERJIhI+BfoCslnnt59/nT/94dE5+994YisNtfrwUkQqiwJ9Hq8cOcPf73+Xv3jlRzP7Nq5q5r999AY+c0e3pi4VkYqkQC/yx//vML//vbdmtu/bvJo/evAOltXpj0pEKptSqsDoZHomzP/sF3r5yMZOjcZFJDIU6AXe/6UXAbi1ezmfvGV1yNWIiFwZDT/zfvv512cef+fRHw+xEhGRq6NAz/uTHxwB4Nlf/pBmKhSRSKr6QM9knZ/5k38B4OObOtmyri3kikRErk5Vn0N3d2789d0z249tuznEakRErk1VB/qLB0/OPN73pZ+gtVFzr4hIdFXtKZfDJy/wyF/uAeCZ/36PwlxEIq8qA30qneW+P3wJgJ/a0s2d67WIhIhEX9UF+uGTF7jpN56f2f6Dn7kjxGpEREqn6gL98WcPAPCBnjYO/+9tIVcjIlI6VfWh6PHhcfb86BwAf73jHhIJXW8uIvFRNSN0d+fDX/4+AI9tvVlhLiKxUxWBns06t/3P785sP/KxG0KsRkSkPKoi0F87cZ4Lk2kADv2v+3Vrv4jEUlUE+n/+2j8D8McP/QfNay4isRX7QJ9IZQBYVpfkP91+fcjViIiUT+wD/TNP5kbnv3bfTSFXIiJSXoEC3cy2mtmbZtZvZo/Pc7zVzL5jZvvM7KCZPVz6Uq/OkaFRAB7+8IaQKxERKa9FA93MksCTwDZgM/CQmW0uavYF4JC73w7cC/y+mdWVuNYr5u5MZbJ86pbVJHWZoojEXJAR+l1Av7sfcfcp4Glge1EbB1osd/lIM3AWSJe00qvw7b0ngNxaoSIicRck0LuBgYLtwfy+Ql8DbgFOAAeAX3H3bPELmdkOM+szs76hoaGrLDm4X/3rvQD85n8s/oVCRCR+ggT6fOcqvGj7fmAvcD1wB/A1M1t+yZPcd7l7r7v3dnZ2XnGxV2IqPfv/yebrLylFRCR2ggT6ILC2YHsNuZF4oYeBZz2nHzgKhLr8z8hECoBfuGd9mGWIiCyZIIH+KrDRzDbkP+h8EHiuqM0x4JMAZrYa2AQcKWWhV6rvnbMAdLU2hlmGiMiSWfS2SXdPm9mjwItAEnjK3Q+a2SP54zuBJ4BvmdkBcqdoHnP302Wse1Fv5y9X7O3Ros8iUh0C3Qfv7ruB3UX7dhY8PgH8RGlLuzZ/05f7HHdTV0vIlYiILI3Y3in6zpkxAJY3aK1QEakOsQz0/YPDANzaratbRKR6xC7Qz41Ozcyu+IV73xdyNSIiSyd2gf7YM/tnHm+9tSvESkREllasAt3d+e6hkwC88cRWLWQhIlUlVoF+4vwEAB/f1ElDbTLkakREllasAv1Y/soWLWQhItUoVoH+5RfeAKBreUPIlYiILL1YBfq+gdzlivfc2B5yJSIiSy82gT49Gdet3cv1YaiIVKXYBPrA2dz58w/f2BFyJSIi4YhNoPefugho7nMRqV6xCfRX89Plvl+BLiJVKjaB/sJruRuK1q1sCrkSEZFwxCLQJ1IZTl+cBKCuJhZdEhG5YrFIv0w2t8Tp/7jvppArEREJTywC/Y33LgCQymQXaSkiEl+xCPSv/MNbANza3RpyJSIi4YlFoHc01wPwyVtWh1yJiEh4YhHoBqxd2UgyoTtERaR6xSLQRUREgS4iEhuxCPTxVIasLnARkSpXE3YBpbBvYJiJtBJdRKpbLEboGXdWNtWFXYaISKgiH+gjEylOjkyi61tEpNpFPtAPn8zdJdrbszLkSkREwhX5QCc/Nt96a1fIdYiIhCsGge5hFyAiUhEiH+ivv5s75ZLNKthFpLoFCnQz22pmb5pZv5k9fpk295rZXjM7aGY/KG2Zl3f09CgAGzq0sIWIVLdFr0M3syTwJHAfMAi8ambPufuhgjYrgK8DW939mJmtKlfBxQbP5RaHvm5Fw1K9pYhIRQoyQr8L6Hf3I+4+BTwNbC9q8zngWXc/BuDup0pb5uXVJBPc0NFEfU1yqd5SRKQiBQn0bmCgYHswv6/QTUCbmf2jme0xs8/P90JmtsPM+sysb2ho6OoqLjJ92aKISLULEujz3bNT/AlkDXAn8GngfuA3zeyS9eDcfZe797p7b2dn5xUXOx93eG9koiSvJSISZUHmchkE1hZsrwFOzNPmtLuPAqNm9hJwO/BWSapcQE0ywYdubC/324iIVLwgI/RXgY1mtsHM6oAHgeeK2nwb+IiZ1ZjZMuBu4PXSljq/kfEU8/8SISJSXRYdobt72sweBV4EksBT7n7QzB7JH9/p7q+b2QvAfiALfNPdXytn4dOOD4/T3da4FG8lIlLRAk2f6+67gd1F+3YWbf8u8LulKy2Y2qSxtm3ZUr+tiEjFifydorXJBCubasMuQ0QkdJEPdNcd/yIiQMQDfXwqw3gqQyqjVBcRiXSgn8xff95cH4uV9ERErkmkA/3E8DgAXa2ax0VEJNKBbpa7/vzGzuaQKxERCV+kA11ERGYp0EVEYiLSgT6QnwtdREQiHuiTqQwAbbqxSEQk2oG+b/A8AF3LdZWLiEikAz030yKsWFYXciUiIuGLdKBPprNhlyAiUjEiHegTqQybVreEXYaISEWI9D3zb568QFNdpLsgIlIykU7D9qY62pvqwy5DRKQiRPqUi5nR2aJAFxGBiAe6iIjMUqCLiMSEAl1EJCYiHej9py7iaLUiERGIcKAPj00BcG40FXIlIiKVIbKBfmEiDcCnNq8OuRIRkcoQ2UCf1tqomRZFRCAGgS4iIjkKdBGRmFCgi4jERGQD/djZ3PJzU5pCV0QEiHCgp7O568/XrmwMuRIRkcoQ2UCftkzT54qIABEO9JROtYiIzBEo0M1sq5m9aWb9Zvb4Au0+YGYZM/ts6Uqc31unLgBQm7Ryv5WISCQsGuhmlgSeBLYBm4GHzGzzZdr9DvBiqYucz/RKRWvali3F24mIVLwgI/S7gH53P+LuU8DTwPZ52n0ReAY4VcL6REQkoCCB3g0MFGwP5vfNMLNu4CeBnQu9kJntMLM+M+sbGhq60lpFRGQBQQJ9vpPUxXPWfgV4zN0zC72Qu+9y91537+3s7Axao4iIBBDkmr9BYG3B9hrgRFGbXuBpMwPoAB4ws7S7/11JqhQRkUUFCfRXgY1mtgE4DjwIfK6wgbtvmH5sZt8C/m+5w/yN9y6U8+VFRCJn0UB397SZPUru6pUk8JS7HzSzR/LHFzxvXi51+csVNX2uiEhOoNss3X03sLto37xB7u7/9drLWpyZ0dpYSzKh69BFRCDCd4qKiMhckQ300ck06Yxu/xcRmRbZma3+Zs9g2CWIiFSUSI7QM/mpczWPi4jIrEgG+rQvfmJj2CWIiFSMSAe6iIjMUqCLiMSEAl1EJCYiGejHz40DMDyWCrkSEZHKEclAn8pff3772taQKxERqRyRDPRp+dkdRUSEiAe6iIjMUqCLiMREJAM968ULJomISCQD/e1TFwGYSmtyLhGRaZEM9JpkruxNq1tCrkREpHJEMtCn6SIXEZFZkQ50ERGZFclAP3RiJOwSREQqTiQD/cRw7tb/61obQq5ERKRyRDLQEwmjs6We9ub6sEsREakYkQx0ERG5lAJdRCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxESgQDezrWb2ppn1m9nj8xz/WTPbn/962cxuL32pIiKykEUD3cySwJPANmAz8JCZbS5qdhT4mLvfBjwB7Cp1oSIisrAgI/S7gH53P+LuU8DTwPbCBu7+srufy2++AqwpbZkiIrKYIIHeDQwUbA/m913OLwLPz3fAzHaYWZ+Z9Q0NDQWvskg262SzWldURKRQkECfb12gedPUzD5OLtAfm++4u+9y91537+3s7AxeZZF/PXpG64mKiBQJEuiDwNqC7TXAieJGZnYb8E1gu7ufKU158zs+PE5jXbKcbyEiEjlBAv1VYKOZbTCzOuBB4LnCBma2DngW+Hl3f6v0Zc61Ylkdbcvqyv02IiKRUrNYA3dPm9mjwItAEnjK3Q+a2SP54zuB3wLaga9bbuXmtLv3lqvopBl3rF1RrpcXEYmkRQMdwN13A7uL9u0sePxLwC+VtjQREbkSulNURCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxEQkA308lQm7BBGRihO5QE9lspwfTzE6lQ67FBGRihK5QE9ncjP3di1vCLkSEZHKErlAn9bRUh92CSIiFSWygS4iInNFLtD/fSC3dOnYpM6hi4gUilygnxtNAXDbGs2HLiJSKHKBPm1d+7KwSxARqSiRDXQREZlLgS4iEhMKdBGRmFCgi4jEhAJdRCQmFOgiIjGhQBcRiQkFuohITCjQRURiQoEuIhITCnQRkZhQoIuIxIQCXUQkJhToIiIxoUAXEYmJQIFuZlvN7E0z6zezx+c5bmb21fzx/Wa2pfSliojIQhYNdDNLAk8C24DNwENmtrmo2TZgY/5rB/CNEtcpIiKLCDJCvwvod/cj7j4FPA1sL2qzHfhzz3kFWGFm15W4VhERWUCQQO8GBgq2B/P7rrQNZrbDzPrMrG9oaOhKawWgq7WBB36si+b6mqt6vohIXAVJRZtnn19FG9x9F7ALoLe395LjQdy5vo071995NU8VEYm1ICP0QWBtwfYa4MRVtBERkTIKEuivAhvNbIOZ1QEPAs8VtXkO+Hz+apcPAufd/d0S1yoiIgtY9JSLu6fN7FHgRSAJPOXuB83skfzxncBu4AGgHxgDHi5fySIiMp9Anyy6+25yoV24b2fBYwe+UNrSRETkSuhOURGRmFCgi4jEhAJdRCQmFOgiIjFhuc8zQ3hjsyHgR1f59A7gdAnLiQL1uTqoz9XhWvq83t075zsQWqBfCzPrc/fesOtYSupzdVCfq0O5+qxTLiIiMaFAFxGJiagG+q6wCwiB+lwd1OfqUJY+R/IcuoiIXCqqI3QRESmiQBcRiYmKDvRqXJw6QJ9/Nt/X/Wb2spndHkadpbRYnwvafcDMMmb22aWsrxyC9NnM7jWzvWZ20Mx+sNQ1llqAn+1WM/uOme3L9znSs7aa2VNmdsrMXrvM8dLnl7tX5Be5qXrfBm4A6oB9wOaiNg8Az5NbMemDwL+GXfcS9PlDQFv+8bZq6HNBu++Tm/Xzs2HXvQR/zyuAQ8C6/PaqsOtegj7/OvA7+cedwFmgLuzar6HPHwW2AK9d5njJ86uSR+jVuDj1on1295fd/Vx+8xVyq0NFWZC/Z4AvAs8Ap5ayuDIJ0ufPAc+6+zEAd496v4P02YEWMzOgmVygp5e2zNJx95fI9eFySp5flRzoJVucOkKutD+/SO5/+ChbtM9m1g38JLCTeAjy93wT0GZm/2hme8zs80tWXXkE6fPXgFvILV95APgVd88uTXmhKHl+BVrgIiQlW5w6QgL3x8w+Ti7Qf7ysFZVfkD5/BXjM3TO5wVvkBelzDXAn8EmgEfgXM3vF3d8qd3FlEqTP9wN7gU8ANwLfM7MfuvtIuYsLScnzq5IDvRoXpw7UHzO7DfgmsM3dzyxRbeUSpM+9wNP5MO8AHjCztLv/3dKUWHJBf7ZPu/soMGpmLwG3A1EN9CB9fhj4sudOMPeb2VHgZuDflqbEJVfy/KrkUy7VuDj1on02s3XAs8DPR3i0VmjRPrv7Bnfvcfce4G+BX45wmEOwn+1vAx8xsxozWwbcDby+xHWWUpA+HyP3GwlmthrYBBxZ0iqXVsnzq2JH6F6Fi1MH7PNvAe3A1/Mj1rRHeKa6gH2OlSB9dvfXzewFYD+QBb7p7vNe/hYFAf+enwC+ZWYHyJ2OeMzdIzutrpn9FXAv0GFmg8CXgFooX37p1n8RkZio5FMuIiJyBRToIiIxoUAXEYkJBbqISEwo0EVEYkKBLiISEwp0EZGY+P/CFaJjYOWW6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rc[0],rc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q3: What is the True positive rate at an FPR of 0.2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your response here\n",
    "#According to the graph, the positive rate is around 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the ROC curve is sometimes too much information, especially if you want to compare performance of many classifiers or datasets. The overall performance is well-characterized by the AUC or Area Under the Curve. Which is exactly what the name suggests, the area under the blue curve. Since a ROC plot lies in a 1 x 1 square, the area is always <= 1.0. A random predictor puts positives and negatives on a diagonal line with slope = 1, and so a random predictor has AUC = 0.5\n",
    "\n",
    "Lets check the AUC for our prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637764912304416"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(testcat6, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critical Thinking: Interpreting AUC scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC score varies between 0.5 (random prediction) and 1.0. A common misconception is that a \"perfect\" predictor, i.e. a predictor that knows the exact probability of a label, will give a score of 1.0. That's incorrect. There are two sources of noise in the generation of a ROC plot:\n",
    "* The difference between the true and predicted probability of a label\n",
    "* The variance introduced by Bernoulli sampling to generate the label\n",
    "\n",
    "The latter is always present and depends on the distribution of label probabilities, the former depends on how good the model is. \n",
    "\n",
    "To see this, imagine a binary label distribution where each data label has a true probability of 0.5. A perfect predictor knows these probabilities but since they all the same, the sorted labels for the ROC plot would still be a random distribution of true and false. The ROC plot would have an AUC of 0.5. AUC scores very close to 1 are possible, but require that the true label distribution include a large fraction of probabilities close to either 1 or 0. That's because the variance of a Bernoulli variable is p(1-p), which is small if p is near 0 or 1. \n",
    "\n",
    "Let's estimate the ROC AUC for a perfect predictor on a similar distribution to our dataset. We can't know this distribution, but we can use the model's prediction  as an approximation to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll generate some uniform random numbers in [0,1], one for each test point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = npr.random(testcat6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll generate Bernoulli random numbers using the predictions as the underlying probability. We use the random numbers we just generated to do that. i.e. to generate a random Bernoulli variable with probability p, you generate a uniform random variable in [0,1] and test if (u < p). The probability that this test succeeds is exactly p. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (a < preds6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860854413384019"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(x, preds6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this number with the AUC you computed earlier. To be clear again what this number is, it is the score of a *perfect* label predictor with the label probability distribution that our classifier has. It is an estimate of how well our classifier could do on this dataset. \n",
    "\n",
    "This secondary AUC calculation is a useful normalizing test when interpreting AUC scores. A common mistake is to assume that a model with AUC 0.85 on dataset A is better (i.e. would score higher on a common dataset) than a model with a score of 0.70 on dataset B. This is not true. It depends strongly on the dataset. The model with score 0.70 may be generating perfect or near-perfect predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 1.00e+00, 1.00e+00, 0.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 0.00e+00, 2.00e+00, 1.00e+00, 2.00e+00, 3.00e+00,\n",
       "        0.00e+00, 3.00e+00, 1.00e+00, 2.00e+00, 5.00e+00, 1.00e+01,\n",
       "        8.00e+00, 6.00e+00, 9.00e+00, 5.00e+00, 1.10e+01, 1.00e+01,\n",
       "        8.00e+00, 2.60e+01, 2.50e+01, 2.00e+01, 2.60e+01, 3.20e+01,\n",
       "        3.30e+01, 4.80e+01, 4.10e+01, 6.00e+01, 6.60e+01, 7.00e+01,\n",
       "        6.90e+01, 9.60e+01, 1.08e+02, 1.19e+02, 1.04e+02, 1.27e+02,\n",
       "        1.38e+02, 1.42e+02, 1.22e+02, 1.31e+02, 1.14e+02, 1.27e+02,\n",
       "        1.52e+02, 1.91e+03]),\n",
       " array([-1.11982006e+01, -1.09742366e+01, -1.07502726e+01, -1.05263086e+01,\n",
       "        -1.03023446e+01, -1.00783806e+01, -9.85441654e+00, -9.63045253e+00,\n",
       "        -9.40648852e+00, -9.18252451e+00, -8.95856049e+00, -8.73459648e+00,\n",
       "        -8.51063247e+00, -8.28666846e+00, -8.06270444e+00, -7.83874043e+00,\n",
       "        -7.61477642e+00, -7.39081241e+00, -7.16684839e+00, -6.94288438e+00,\n",
       "        -6.71892037e+00, -6.49495636e+00, -6.27099235e+00, -6.04702833e+00,\n",
       "        -5.82306432e+00, -5.59910031e+00, -5.37513630e+00, -5.15117228e+00,\n",
       "        -4.92720827e+00, -4.70324426e+00, -4.47928025e+00, -4.25531623e+00,\n",
       "        -4.03135222e+00, -3.80738821e+00, -3.58342420e+00, -3.35946019e+00,\n",
       "        -3.13549617e+00, -2.91153216e+00, -2.68756815e+00, -2.46360414e+00,\n",
       "        -2.23964012e+00, -2.01567611e+00, -1.79171210e+00, -1.56774809e+00,\n",
       "        -1.34378407e+00, -1.11982006e+00, -8.95856049e-01, -6.71892037e-01,\n",
       "        -4.47928025e-01, -2.23964012e-01, -1.57446228e-10]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(preds6),50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is an enormous range of values. Most probabilities are very close to zero or one, which is why this dataset has such a high ROC AUC score.\n",
    "\n",
    "Suppose instead we had a dataset with a less wide distribution. We can use a lognormal distribution to simulate this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = np.minimum(npr.lognormal(-4,1,10000),1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty good model, e.g. for the range of user's probabilities of clicking on an ad. Let's look at a histogram of the log10 of the values (a direct histogram will be too squashed near 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   3.,    5.,   14.,   33.,   87.,  198.,  391.,  701., 1075.,\n",
       "        1338., 1436., 1532., 1203.,  896.,  591.,  270.,  138.,   57.,\n",
       "          25.,    7.]),\n",
       " array([-3.51156332, -3.3466016 , -3.18163988, -3.01667816, -2.85171643,\n",
       "        -2.68675471, -2.52179299, -2.35683127, -2.19186955, -2.02690782,\n",
       "        -1.8619461 , -1.69698438, -1.53202266, -1.36706093, -1.20209921,\n",
       "        -1.03713749, -0.87217577, -0.70721405, -0.54225232, -0.3772906 ,\n",
       "        -0.21232888]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log10(cprob),20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's our distribution of virtual users. Notice that the values (which represent click probabilities) range over several orders of magnitude since we plotted their log10. Next we simulate users' click behavior. Once again we generate a uniform random variable u for each user, and output 1 if u < the user's click probability given by cprob. \n",
    "\n",
    "Finally we compute the AUC on that data, which is the score of a perfect predictor on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478231220516866"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = npr.random(cprob.shape)\n",
    "x = (a < cprob)\n",
    "roc_auc_score(x, cprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's the AUC score for a perfect predictor on this (artificial) dataset. This is lower than the *real* predictions on the RCV1 text dataset. So be careful when interpreting AUC scores. There is no absolute scale for them, and they depend a lot on the dataset.\n",
    "\n",
    "Another important point is that the AUC value for mid-range scores can have quite a lot of variance. Try re-evaluating the last cell to see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q4: What changes do you think you should make to the distribution cprob to increase the ROC AUC score?\n",
    ">Instead of inspecting numerous confusion matrices, we can try to figure out the best threashold. Sicne it is better to automatically calculate TP and FP rates at the threshold and visualize all results along a ROC curve. From this, we can also concldue which threasholds give us the best accuracy.\n",
    "If we different threashold values, the distibution of cprob to increase the ROC AUC score. \n",
    "which threashold might give us the best accuracy.If you had a distribution with less 0's it woudl perfom better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are an extremely accurate classifier for datasets of moderate size. Let's try them out here. We'll load the MNIST data now, but first its probably a good idea to restart your kernel to reduce memory use. Click on the \"Kernel\" menu above and then \"Restart\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0=np.loadtxt(\"train.fmat.txt\")\n",
    "test0=np.loadtxt(\"test.fmat.txt\")\n",
    "train = np.transpose(train0[:,0:4000])\n",
    "test = np.transpose(test0[:,0:2000])\n",
    "traincats = np.loadtxt(\"ictrain.imat.txt\")\n",
    "testcats = np.loadtxt(\"ictest.imat.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we're going to tuning the parameters of RFs on some test data, we need to split our test set into a validation set and a final test set to avoid overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = test[0:1000,:]\n",
    "finaltest = test[1000:2000,:]\n",
    "validationcats = testcats[0:1000]\n",
    "finaltestcats = testcats[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=30, n_estimators=20, n_jobs=4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=20,n_jobs=4,bootstrap=True)\n",
    "rfclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.883"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "np.mean(preds == validationcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the [scikit-learn documentation for Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier) to make sure you understand the meaning of all the parameters in the call to the RandForestClassifier constructor. Which ones do you think will improve accuracy the most? **NOTE** you don't need to tune n_jobs. Its the number of threads that the classifier code runs and it only affects running time. It should be set to the number of cores that your processor has. \n",
    "\n",
    "Try tuning the classifier with the validation set above to get better than 90% accuracy on the validation set. Don't touch the final test set until you're done tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q5: Make a table with at least two values you tried each for criterion, max_features, n_estimators, and bootstrap. What trends to you notice for each one? \n",
    "\n",
    "> Q6: Report your validation and final test accuracy. Include all the parameters you used, e.g., include the line where you invoked the RandomForestClassifier constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier(criterion='entropy',max_features=40,n_estimators=80,n_jobs=4,bootstrap=True)\n",
    "rfclassifier\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "np.mean(preds == validationcats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: code and response for Q5 here\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=40,n_jobs=4,bootstrap=False)\n",
    "rfclassifier\n",
    "rfclassifier.fit(train,traincats)\n",
    "preds = rfclassifier.predict(validation)\n",
    "np.mean(preds == validationcats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Accuracy     | 0.914   | 0.926 |\n",
    "|--------------|---------|-------|\n",
    "| criterion    | entropy | gini  |\n",
    "| max_features | 40      | 30    |\n",
    "| n_estimators | 80      | 40    |\n",
    "| bootstrap.   | True    | False |\n",
    "\n",
    "\n",
    "I noticed that when the bootstrap is false, the accuracy is higher.\n",
    "Also if the number are the same for max_features and n_estimators while bootstrap is true, the accuracy is higher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_features=30, n_estimators=40,\n",
       "                       n_jobs=4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: response/code for Q6 here (either a written response or reporting with code are fine)\n",
    "\n",
    "rfclassifier = RandomForestClassifier(criterion='gini',max_features=30,n_estimators=40,n_jobs=4,bootstrap=False)\n",
    "rfclassifier\n",
    "rfclassifier.fit(train,traincats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rfclassifier.predict(finaltest)\n",
    "np.mean(preds == finaltestcats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q7: Reflect on and explain any differences between your validation and final test accuracy scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first I tried different numbers for max_features and n_estimators, figured out which ones give me the best accuracy. After trying a lot of numbers, I changed the criterion and the bootstrap to see if that made any difference. The code with where bootstrap is false, has a higher accuracy than one where it is true. It seems to me that the criterion did not make much of a difference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Your Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit this notebook on Canvas under Lab 7 by Friday, November 6th at 11:59PM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
